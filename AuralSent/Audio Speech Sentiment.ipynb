{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a44971-89cc-4b21-813e-1dca494bd603",
   "metadata": {},
   "source": [
    "#Audio Speech Sentiment\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/imsparsh/audio-speech-sentiment/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c715546-b9a8-40f9-950a-9ab723dfe503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import speech_recognition as sr\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "# Initialize tqdm for pandas apply()\n",
    "tqdm.pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d4b2b-c8b7-4426-9d63-74af4349c51b",
   "metadata": {},
   "source": [
    "### **Loading the Dataset**\n",
    "\n",
    "Load your dataset to get a DataFrame that includes the paths to your audio files and their corresponding sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f452a279-4e24-4a34-8c18-eee75da3a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Class</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346.wav</td>\n",
       "      <td>Negative</td>\n",
       "      <td>archive2/TRAIN/346.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.wav</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>archive2/TRAIN/163.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>288.wav</td>\n",
       "      <td>Negative</td>\n",
       "      <td>archive2/TRAIN/288.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279.wav</td>\n",
       "      <td>Negative</td>\n",
       "      <td>archive2/TRAIN/279.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244.wav</td>\n",
       "      <td>Negative</td>\n",
       "      <td>archive2/TRAIN/244.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename     Class               full_path\n",
       "0  346.wav  Negative  archive2/TRAIN/346.wav\n",
       "1  163.wav   Neutral  archive2/TRAIN/163.wav\n",
       "2  288.wav  Negative  archive2/TRAIN/288.wav\n",
       "3  279.wav  Negative  archive2/TRAIN/279.wav\n",
       "4  244.wav  Negative  archive2/TRAIN/244.wav"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPath = 'archive2/TRAIN/'\n",
    "df_base = pd.read_csv('archive2/TRAIN.csv')\n",
    "df_base['full_path'] = df_base['Filename'].apply(lambda x: trainPath + x)\n",
    "\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e6c19-cfee-4c15-982e-9a5522645bfa",
   "metadata": {},
   "source": [
    "### **Audio to Text Conversion**\n",
    "\n",
    "Convert the audio files to text using the SpeechRecognition library. This process can be time-consuming, especially for large datasets, and its accuracy depends on the quality of the audio and the clarity of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7b7d3f-6c3a-4aae-ba43-f1efe4860601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031f6121ab254dd1b73d0dec2d45e253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming df_base is your DataFrame and it has a 'full_path' column with audio file paths\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def audio_to_text(path):\n",
    "    try:\n",
    "        with sr.AudioFile(path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text, False  # Text and a flag indicating no error\n",
    "    except (sr.UnknownValueError, sr.RequestError, ValueError) as e:\n",
    "        return \"Error: \" + str(e), True  # Indicate an error occurred\n",
    "\n",
    "# Apply the function with progress tracking\n",
    "# The result is a DataFrame with two columns from the tuple returned by audio_to_text\n",
    "df_base[['transcript', 'error']] = df_base['full_path'].progress_apply(lambda x: pd.Series(audio_to_text(x)))\n",
    "\n",
    "# Filter out the errors if necessary\n",
    "df_base_clean = df_base[df_base['error'] == False].drop(columns=['error'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb8687-41c6-47bd-b2df-d1ed484c0c2a",
   "metadata": {},
   "source": [
    "### **Prepare Text Data for T5**\n",
    "\n",
    "Format the transcripts as input for the T5 model. You might consider adding a prefix like `\"classify sentiment:\"` to each text to make it explicit that you're asking the model to classify the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727eed35-00a5-4e47-ace2-025b15da09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_clean['formatted_text'] = \"classify sentiment: \" + df_base_clean['transcript']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b541e-4fa6-4655-a483-af1f9c747247",
   "metadata": {},
   "source": [
    "### **Load and Setup T5 Model**\n",
    "\n",
    "Ensure you have the `transformers` library installed, and then load the T5 model along with its tokenizer. You can choose a model size that balances between performance and computational efficiency, such as `t5-small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798bb6b8-b66f-477b-86d6-a90a661f55d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28778692-f0d2-4e84-8bec-432fceb8c7cc",
   "metadata": {},
   "source": [
    "### **Sentiment Analysis with T5**\n",
    "\n",
    "Iterate over the formatted text and use the T5 model to predict the sentiment. Given the potentially large number of texts, consider batching this operation or using a subset of data to test your setup first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc2bf65-267c-4ab9-9305-ea0b73e8454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avielstein/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/var/folders/d2/n_5_62n524v01v1vk59vwv0h0000gn/T/ipykernel_18248/774655060.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['sentiment'] = subset_df['formatted_text'].apply(predict_sentiment)\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example: applying the prediction in batches or on a subset\n",
    "# For large datasets, consider using DataLoader from torch.utils.data or similar batching techniques\n",
    "subset_df = df_base_clean.head(20)  # Example: working with a small subset for testing\n",
    "subset_df['sentiment'] = subset_df['formatted_text'].apply(predict_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48de0cd-9376-4bfb-89fc-fa4dcaa951a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc3693a244c4452820f7d662565b5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "testPath = 'archive2/TEST/'\n",
    "test_files = [f for f in os.listdir(testPath) if f.endswith('.wav')]\n",
    "df_test = pd.DataFrame(test_files, columns=['Filename'])\n",
    "df_test['full_path'] = df_test['Filename'].apply(lambda x: os.path.join(testPath, x))\n",
    "\n",
    "\n",
    "df_test['transcript'] = df_test['full_path'].progress_apply(lambda x: audio_to_text(x)[0])\n",
    "\n",
    "\n",
    "df_test['formatted_text'] = \"classify sentiment: \" + df_test['transcript']\n",
    "\n",
    "# Example function for sentiment prediction, assuming T5 model is already loaded\n",
    "def predict_sentiment(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "df_test['predicted_sentiment'] = df_test['formatted_text'].progress_apply(predict_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
