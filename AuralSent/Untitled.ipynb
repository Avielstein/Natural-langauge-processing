{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fb5ea1-6d59-4150-a7d0-089b30a54397",
   "metadata": {},
   "source": [
    "# AuralSent: Harmonizing Text and Sound for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f97e5b7-9298-4754-bd75-7b796aec8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SpeechRecognition\n",
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97f1daa-fafd-4d61-99fa-5d70a4ae6bba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (361317769.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Data:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Data:\n",
    "\n",
    "https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio/datae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83559727-0858-4fbe-8907-20744e1003ac",
   "metadata": {},
   "source": [
    "### Preprocessing Acoustic Data\n",
    "Extract Mel-Frequency Cepstral Coefficients (MFCCs) and other relevant features from audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d768ee0-007f-4154-8f97-14be3c9edb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_acoustic_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    pitch, _ = librosa.piptrack(y=y, sr=sr)\n",
    "    energy = np.array([\n",
    "        np.sum(np.abs(y[i:i+512])**2)\n",
    "        for i in range(0, len(y), 512)\n",
    "    ])\n",
    "    return mfccs, pitch, energy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f4512-08c3-49a7-ae7e-e0da8211a46f",
   "metadata": {},
   "source": [
    "### Text Transcription\n",
    "Transcribe audio to text using speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13523999-2b0f-45c7-b5bf-3e45402bac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "    except sr.UnknownValueError:\n",
    "        text = \"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae382c06-6c71-4a10-bce9-3f2eb31608a9",
   "metadata": {},
   "source": [
    "### [TODO] Align Text with Acoustic Features\n",
    "\n",
    "\n",
    "This step is conceptual as exact alignment depends on the specific requirements and dataset. One approach is to segment audio at natural speech pauses and extract features per segment, aligning them with transcribed text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe8be9-e40e-43d7-a411-50fb14a26b11",
   "metadata": {},
   "source": [
    "### Step 5: Integrate Acoustic Features into Text Representation\n",
    "Represent acoustic features in a compatible format for T5. This could involve encoding features numerically and appending them to the text or using special tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91c1a4c-64ad-4b05-8763-db66dfcbc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_features_with_text(text, features):\n",
    "    # Example of simple integration; customize based on your approach\n",
    "    feature_representation = \" \".join([str(f) for f in features])\n",
    "    return f\"{text} [FEATURES] {feature_representation}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
