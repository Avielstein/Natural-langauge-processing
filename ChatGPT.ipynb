{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b75c418-69ff-4ec9-bbab-619c3037e717",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Documentation\n",
    "https://platform.openai.com/docs/api-reference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60adbd66-6ec9-4b61-9eee-601ad775efe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25hm##################\u001b[0m) â ¸ reify:web-streams-polyfill: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://r\u001b[0m\u001b[Kps://r\u001b[0m\u001b[K\n",
      "added 30 packages, and audited 49 packages in 3s\n",
      "\n",
      "11 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
     ]
    }
   ],
   "source": [
    "#DOWNLOADS:\n",
    "#!pip install openai\n",
    "#!npm install openai@^4.0.0\n",
    "#!node -v\n",
    "#!echo $PATH\n",
    "\n",
    "#was having issues with the path for node\n",
    "#import os\n",
    "#os.environ['PATH'] += ':/usr/local/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7094b671-e2f5-4240-95a3-e5fd55cd8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2c891b-9ca1-4b0b-8c1c-e041d3f1d6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!openai migrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dfc81b9-6160-4fd8-9b4a-3a263baf2a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911caa39-5caf-48b7-a54d-a107df119ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GET from config.json\n",
    "import json\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    openai.api_key = config['OPENAI_API_KEY'] #UPDATE CONFIG\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bee8966-d074-4432-8765-ac4e066e9900",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m user_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreate a small dataset about total sales over the last year. The format of the dataset should be a data frame with 12 rows and 2 columns. The columns should be called \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_sales_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column should contain the shortened forms of month names from \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJan\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDec\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_sales_usd\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column should contain random numeric values taken from a normal distribution with mean 100000 and standard deviation 5000. Provide Python code to generate the dataset, then provide the output in the format of a markdown table.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a dataset using GPT\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_msg},\n\u001b[1;32m     10\u001b[0m                                          {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_msg}])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_proxy.py:22\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_proxied__(), attr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_proxy.py:43\u001b[0m, in \u001b[0;36mLazyProxy.__get_proxied__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_proxied__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_cache:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__load__()\n\u001b[1;32m     45\u001b[0m     proxied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__proxied\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxied \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/lib/_old_api.py:33\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__load__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__load__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# Define the system message\n",
    "system_msg = 'You are a helpful assistant who understands data science.'\n",
    "\n",
    "# Define the user message\n",
    "user_msg = 'Create a small dataset about total sales over the last year. The format of the dataset should be a data frame with 12 rows and 2 columns. The columns should be called \"month\" and \"total_sales_usd\". The \"month\" column should contain the shortened forms of month names from \"Jan\" to \"Dec\". The \"total_sales_usd\" column should contain random numeric values taken from a normal distribution with mean 100000 and standard deviation 5000. Provide Python code to generate the dataset, then provide the output in the format of a markdown table.'\n",
    "\n",
    "# Create a dataset using GPT\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                        messages=[{\"role\": \"system\", \"content\": system_msg},\n",
    "                                         {\"role\": \"user\", \"content\": user_msg}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3470-1fdb-42fa-8b69-df8d813d8030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d890f2c-a1e7-4241-b778-611ba3d8404b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
