{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d067395-434c-4918-b9ea-066a7d2838d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install huggingface_hub\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "#!pip install --upgrade tensorflow\n",
    "#!pip install transformers\n",
    "#!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab144-8f5c-4baf-b6fc-ecab81cf2041",
   "metadata": {},
   "source": [
    "## OG Hugging face \n",
    "\n",
    "https://huggingface.co/google/flan-t5-small#using-the-pytorch-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24d74f-153d-450a-bad1-4d66351d87e1",
   "metadata": {},
   "source": [
    "## reviews tutorial\n",
    "\n",
    "https://medium.com/@YasinShafiei/text-summarization-with-deep-learning-python-with-tensorflow-d0f3e329c3d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e264a789-7f52-497e-857e-25a06834751a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/avielstein/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/avielstein/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/avielstein/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /Users/avielstein/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0704426-4f58-46b3-af78-29e5af1a26e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b91952e-e5a1-42b3-a5e6-9da57db47386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a246d4c1253341698df69e81b9887d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2a68f782074aa0ac6b584852075e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cdad838fcc47178ca76b46fea17d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8195f75ce61449e893a7395335cec629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5958ca7030a420881bdf65fb4df4a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870f3bd4cac14e258bfe10937b9b214f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f5c8f7df304432872ab32cf6d79a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee18bcdb-9c44-4bb5-b51e-40f353761e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\" Damn, what a spot. For game day there is no better place than right here at Fred's. What a great time. The bartender Mathew took awesome care of us and he ran the bar like a boss. How can it get any better when the big man himself is on the More\n",
    "\n",
    "Absolutely outstanding experience. Came up for the LSU WS Championship game (which they won  go ðŸ… ðŸ¯). Atmosphere was fantastic with a great student culture. Really impressed by both Peytonâ€™s outstanding bar-backing and Morganâ€™s amazing bartending. They both definitely held down a very, very busy fort. Will be back! â€¦More\n",
    "\n",
    "If you're looking for a great place to unwind, listen to music or cheer on your favorite college team, look no further! Fred's is the place to be for college game days! â€¦More\n",
    "\n",
    "Place to go for after football games!! I will say, it is quite a walk from the stadium, so be prepared for that. Lot of people and great vibes!!\n",
    "\n",
    "Amazing spot! Owner knows how to do it! Expansion is a good move! Always have a good time here! â€¦More\n",
    "\n",
    "Kinda rowdy on the patio. Good bar but the music wasn't exactly great.\n",
    "\n",
    "Itâ€™s an undergrad bar, but actually surprisingly clean â€¦More\n",
    "\n",
    "Paid double cover charge for an event that was falsely advertised... Cover charge, drink prices AND event all falsely advertised. Place was too packed to dance, but at least the drinks were good. Anyway, NEVER AGAIN.\n",
    "\n",
    "Attractive and polite bartenders,  but the DJ NEVER plays requests. Suppose he doesn't have to do anything but what he wants...still in all...\n",
    "\n",
    "It really takes forever to get your drink. And the bartenders absolutely do not go in order of who was waiting first. Not really that fun because they let way too many people in there and it gets so crowded you cant even dance. More of a â€¦More\n",
    "\n",
    "My son and a friend went to this bar after a game. A server told  my African American Son he didn't belong. This bar deserves absolutely No stars for character ðŸ˜’.  Enough said... I'll allow the reader to ponder.\n",
    "\n",
    "Definitely a young college bar only. Probably a great place for gamedays. Staff was cool. I'm only 29 but i felt super old being in there. Watched one idiot customer think it was funny to snap a pool cue over his head for a picture. And â€¦More\n",
    "Like\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70920e27-2f7e-4f54-aeaf-50f52b35b697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is an example sentence it has punctuation stopwords and different cases\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def cleaned_text(text):\n",
    "    # Lowercasing the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Join the cleaned tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage:\n",
    "text_to_clean = \"This is an example sentence! It has punctuation, stopwords, and different cases.\"\n",
    "cleaned_text = cleaned_text(text_to_clean)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8da5fda5-ed29-4ace-98e6-8df796639080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damn what a spot for game day there is no better place than right here at freds what a great time the bartender mathew took awesome care of us and he ran the bar like a boss how can it get any better when the big man himself is on the more absolutely outstanding experience came up for the lsu ws championship game which they won go ðŸ… ðŸ¯ atmosphere was fantastic with a great student culture really impressed by both peyton â€™ s outstanding barbacking and morgan â€™ s amazing bartending they both definitely held down a very very busy fort will be back â€¦more if youre looking for a great place to unwind listen to music or cheer on your favorite college team look no further freds is the place to be for college game days â€¦more place to go for after football games i will say it is quite a walk from the stadium so be prepared for that lot of people and great vibes amazing spot owner knows how to do it expansion is a good move always have a good time here â€¦more kinda rowdy on the patio good bar but the music wasnt exactly great it â€™ s an undergrad bar but actually surprisingly clean â€¦more paid double cover charge for an event that was falsely advertised cover charge drink prices and event all falsely advertised place was too packed to dance but at least the drinks were good anyway never again attractive and polite bartenders but the dj never plays requests suppose he doesnt have to do anything but what he wantsstill in all it really takes forever to get your drink and the bartenders absolutely do not go in order of who was waiting first not really that fun because they let way too many people in there and it gets so crowded you cant even dance more of a â€¦more my son and a friend went to this bar after a game a server told my african american son he didnt belong this bar deserves absolutely no stars for character ðŸ˜’ enough said ill allow the reader to ponder definitely a young college bar only probably a great place for gamedays staff was cool im only 29 but i felt super old being in there watched one idiot customer think it was funny to snap a pool cue over his head for a picture and â€¦more like\n"
     ]
    }
   ],
   "source": [
    "text = input_text.lower()\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "tokens = word_tokenize(text)\n",
    "cleaned_text = ' '.join(tokens)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "87583388-7f78-405e-853c-aecc8383de25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt\n",
    "#p = 'add a summary: '\n",
    "#p = 'add a detailed summary: '\n",
    "#p = 'Summarize:  '\n",
    "#p = 'give a long summary: '\n",
    "#p = 'is this a good bar:  '\n",
    "#p = 'do they have beer?: '\n",
    "p = 'Translate all to Spanish: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ea1c6-2ea1-43b6-b493-b0bf27eeff23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "aad2913d-ac07-4b88-88a3-1e3282cf1540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More More More Mor\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(p+input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
